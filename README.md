This repository provides a set of customized tensorflow (+Keras) python script used for the experimental part of the following publications:

* E. Russo et al., "DNN Model Compression for IoT Domain Specific Hardware Accelerators," in IEEE Internet of Things Journal, doi: 10.1109/JIOT.2021.3111723.
* E. Russo, M. Palesi, S. Monteleone, D. Patti, G. Ascia and V. Catania, "LAMBDA: An Open Framework for Deep Neural Network Accelerators Simulation," 2021 IEEE International Conference on Pervasive Computing and Communications Workshops and other Affiliated Events (PerCom Workshops), 2021, pp. 161-166, doi: 10.1109/PerComWorkshops51409.2021.9431078.
* G. Ascia, V. Catania, A. Mineo, S. Monteleone, M. Palesi and D. Patti, "Improving Inference Latency and Energy of DNNs through Wireless Enabled Multi-Chip-Module-based Architectures and Model Parameters Compression," 2020 14th IEEE/ACM International Symposium on Networks-on-Chip (NOCS), 2020, pp. 1-6, doi: 10.1109/NOCS50636.2020.9241714.
* H. Lahdhiri et al., "DNNZip: Selective Layers Compression Technique in Deep Neural Network Accelerators," 2020 23rd Euromicro Conference on Digital System Design (DSD), 2020, pp. 526-533, doi: 10.1109/DSD51259.2020.00088.
* G. Ascia, V. Catania, J. Jose, S. Monteleone, M. Palesi and D. Patti, "Improving Inference Latency and Energy of Network-on-Chip based Convolutional Neural Networks through Weights Compression," 2020 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW), 2020, pp. 54-63, doi: 10.1109/IPDPSW50202.2020.00017.
* Giuseppe Ascia, Vincenzo Catania, Salvatore Monteleone, Maurizio Palesi, Davide Patti, and John Jose. 2019. Analyzing networks-on-chip based deep neural networks. In Proceedings of the 13th IEEE/ACM International Symposium on Networks-on-Chip (NOCS '19). Association for Computing Machinery, New York, NY, USA, Article 23, 1â€“2.

Features:
* Easyloading of h5 weights to evaluate on ImageNet
* Support of quantized versions
